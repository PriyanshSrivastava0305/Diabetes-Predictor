# -*- coding: utf-8 -*-
"""Diabities.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PoHXxndWCtND96gYtBj-qbkluil5Vj8l

# **Problem Statement**

The project aims to develop a predictive model to identify individuals at risk of diabetes using health metrics such as blood glucose, blood pressure, skin thickness, insulin levels, and BMI. By analyzing this dataset, the model will classify individuals as diabetic or non-diabetic, assisting healthcare professionals in early intervention and management of diabetes to enhance patient outcomes.

# **Objectives**

1.**Data** **Cleaning**: Address missing values and outliers in key columns, ensuring valid zero values are retained in "Pregnancy" while correcting abnormal values in "SkinThickness" and "Insulin."

2.**Exploratory** **Data** **Analysis**: Investigate feature relationships to uncover patterns and correlations within the dataset.

3.**Model Training and Evaluation**: Train machine learning classifiers to predict diabetes risk and assess their performance for effective early detection.
The project aims to create a robust, interpretable model for early diabetes detection.

#**Review of the Solution**

The solution to the diabetes risk prediction project incorporates various tools and libraries that enhance data analysis, visualization, and model development. Below is a detailed overview of the solution, highlighting the specific libraries utilized:


**1. Data Preparation**

  Data Cleaning

  Libraries Used

Pandas: For data manipulation and cleaning tasks, such as handling missing values and outliers in health metrics.

NumPy: For numerical operations and handling arrays efficiently, particularly useful in data cleaning processes.

**2. Exploratory Data Analysis**

Pattern and Correlation Analysis

Libraries Used

Matplotlib: Employed for creating various types of plots (e.g., histograms, scatter plots) to visualize distributions and relationships between features.

Seaborn: Utilized for advanced data visualization, providing attractive and informative statistical graphics. It helps in visualizing correlations and distributions effectively.

**3. Model Development**

Machine Learning Model Training

Libraries Used

Scikit-learn: This library is essential for implementing supervised learning algorithms. It provides tools for model training, testing, and evaluation.

NumPy: Again utilized here for scientific computing tasks, such as array manipulations during model training.

**4. Model Evaluation**

Performance Assessment

Libraries Used

Scikit-learn: Also used for evaluating model performance through metrics like accuracy, precision, recall, F1 score, and confusion matrices.

**5. Implementation and Interpretation**

Deployment of the Model

The final model can be integrated into healthcare systems or applications to assist healthcare professionals in identifying high-risk individuals.

Interpretable Results:

The use of visualization libraries like Matplotlib and Seaborn aids in presenting the results clearly, making it easier for healthcare providers to understand the factors contributing to diabetes risk.

#**Description of Dataset**

This dataset consists of records for multiple individuals, with each record containing information about various physiological and demographic factors that could influence diabetes risk. The target variable (usually called Outcome) indicates whether the individual has diabetes (1) or not (0).


Key Features:

Pregnancies: Number of times the patient has been pregnant.

Glucose: Plasma glucose concentration.

BloodPressure: Diastolic blood pressure.

SkinThickness: Triceps skinfold thickness.

Insulin: 2-hour serum insulin.

BMI: Body Mass Index.

DiabetesPedigreeFunction: A function that scores the likelihood of diabetes based on family history.

Age: Age of the patient.

Outcome: The target variable, where 1 indicates diabetes and 0 indicates no diabetes.

# **Indivitual Contributions**

Hemant Raj (2206027) : Data Visualization

Ashish Singh (2206082) : Data Ploting

Pratyush Prasoon (2206107) : Model training using sklearn

Prithvi Roy (2206108) : Data Cleaning

Priyansh Srivastava (2206110) : Finding dataset and summarizes statistical details

Shubhradip Dutta (2206129) : Model evaluation

Ashish Patra (2206170) : Data splitting
"""

import pandas as pd

df=pd.read_csv(r"/content/diabetes.csv")

#Displays the first five rows
df.head()

#Displays the last five rows
df.tail()

#Provides information on column types and memory
df.info()

#Summarizes statistical details
df.describe()

#Counts unique values per column
df.nunique()

#Checks for missing values
df.isnull().sum()

df.dropna(inplace=True)

df.isnull().sum()

df.duplicated().sum()

df.columns

"""# **Data** **Visualization** :"""

import matplotlib.pyplot as plt
import seaborn as sns

#Line graph Glucose vs. Age

plt.figure(figsize=(20,10))
sns.lineplot(y='Glucose',x='Age',c="r",marker="^",mfc="g",mec="b",data=df,alpha=0.7,lw=3)
plt.title("Diabetes")
plt.grid()
plt.show()

#Bar graph Glucose vs. Age grouped by BMI

plt.figure(figsize=(30,20))
sns.barplot(x='Glucose',y='Age',hue='BMI',width=1,data=df)
plt.legend(title='BMI',title_fontsize="30",fontsize="30")
plt.title("Diabetes",size=40)
plt.ylabel("Age",size=30)
plt.xlabel("Glucose",size=30)
plt.show()

#Bar graph Age vs. Glucose grouped by BMI

plt.figure(figsize=(30,20))
sns.barplot(x='Age',y='Glucose',hue='BMI',width=1,data=df)
plt.legend(title='BMI',title_fontsize="30",fontsize="30")
plt.title("Diabetes",size=40)
plt.ylabel("Age",size=30)
plt.xlabel("Glucose",size=30)
plt.show()

#Pair graph Pairwise relationships

sns.pairplot(hue='Glucose',data=df)
plt.show()

sns.pairplot(hue='BMI',data=df)
plt.show()

#line graph

plt.figure(figsize=(15,7))
plt.title("Diabetes Outcome")
sns.lineplot(y='Insulin',x='Age',marker="o",c="g",mfc="b",mec="r",ls="--",data=df)
plt.grid()
plt.show()

#bar graph

sns.barplot(df)
plt.title("Diabetes Outcome")
plt.show()

#scatter plot

sns.scatterplot(df)
plt.title("Diabetes Outcome")
plt.show()

#line graph insulin bs BMI

plt.figure(figsize=(8,8))
plt.title("Diabetes Outcome")
sns.lineplot(x='Insulin',y='BMI',c="r",marker="o",mfc="g",mec="b",data=df,alpha=1,lw=0.5)
plt.grid(axis="y")
plt.show()

sns.catplot(df, kind='strip', height=6, aspect=2)
plt.title("Diabetes Outcome")
plt.show()

sns.lineplot(y='BMI',x='Outcome',data=df)
plt.title("Diabetes Outcome")
plt.show()

sns.histplot(x='BMI',y='Outcome',data=df)
plt.title("Diabetes Outcome")
plt.show()

sns.boxplot(df)
plt.title("Diabetes Outcome")
plt.show()

sns.kdeplot(x='BMI',y='Outcome',data=df)
plt.title("Diabetes Outcome")
plt.show()

sns.heatmap(df.corr(),cmap="Purples",annot=True)
plt.title("Diabetes Outcome")
plt.show()

"""# **Machine Learning :**

"""

#sklearn for data splitting, preprocessing, model training, and evaluation.

import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

df

# Separate features (X) and target (y)
X = df.drop(['Outcome'], axis=1)  # Keep all other columns as features
y = df['Outcome']  # Target variable

X

y

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print(X.shape)
print(X_train.shape)
print( X_test.shape)

X_test

y_test

y_train

y_test

#binary classification
model= LogisticRegression()
model.fit(X_train, y_train)

prediction_on_training_data = model.predict(X_train)
accuracy_on_training_data = accuracy_score(y_train,prediction_on_training_data)

print("Accuracy on training data: ",accuracy_on_training_data)

prediction_on_test_data=model.predict(X_test)
accuracy_on_test_data=accuracy_score(y_test,prediction_on_test_data)

print("Accuracy on testing data: ",accuracy_on_test_data)

#Measures the proportion of correct predictions both on training and test data
model.score(X,y)

"""# **Model Prediction:**

"""

input_data = [[0, 93, 60, 25, 92, 28.7, 0.532, 22]]
Prediction = model.predict(input_data)

if Prediction == 1: #diabitic 1, not diabitic 0
  print("Diabitic")
else:
  print("Not Diabitic")

"""# **Indivitual Contribution**

Hemant Raj (2206027) : Data Visualization

Ashish Singh (2206082) : Data Ploting

Jay Kumar (2206094) : Documentation

Pratyush Prasoon (2206107) : Model training using sklearn

Prithvi Roy (2206108) : Data Cleaning

Priyansh Srivastava (2206110) : Finding dataset and summarizes statistical details

Shubhradip Dutta (2206129) : Model evaluation

Ashish Patra (2206170) : Data splitting





"""

